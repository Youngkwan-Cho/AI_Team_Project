{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3Y_XlLIs_om"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from google.colab import drive\n",
        "from datetime import datetime, timedelta\n",
        "drive.mount('/content/drive')\n",
        "np.random.seed(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qZDlzrskAGAV"
      },
      "outputs": [],
      "source": [
        "#train1 labeling 및 전처리\n",
        "text = \"root1_220823174615.jpg\"\n",
        "n = 7\n",
        "result = text[6:n+11]\n",
        "date_time = datetime.strptime(result, \"%y%m%d%H%M%S\")\n",
        "formatted_date_time = date_time.strftime(\"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
        "\n",
        "output_list = []\n",
        "\n",
        "for _ in range(6):\n",
        "    delta = timedelta(minutes=720)\n",
        "\n",
        "    # 시간 증가\n",
        "    new_date_time = date_time + delta\n",
        "\n",
        "    # 증가된 시간 출력\n",
        "    formatted_date_time = new_date_time.strftime(\"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
        "\n",
        "    date_time = datetime.strptime(formatted_date_time, \"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
        "    formatted_number = date_time.strftime(\"%y%m%d%H%M%S\")\n",
        "\n",
        "    output_list.append(int(formatted_number))\n",
        "\n",
        "image_directory = \"/content/drive/MyDrive/root1_220823\"\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "# Iterate over the files in the directory\n",
        "for filename in os.listdir(image_directory):\n",
        "    # Read the image\n",
        "    image = cv2.imread(os.path.join(image_directory, filename))\n",
        "    \n",
        "    # Check if image is not empty\n",
        "    if image is not None:\n",
        "        # Resize the image to match the MNIST dataset size (32x32 pixels)\n",
        "        try:\n",
        "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            gray_image  = gray_image[:, 80:-60] \n",
        "            gray_image = cv2.resize(gray_image, (32, 32))\n",
        " \n",
        "            x_train.append(gray_image)\n",
        "            text = filename\n",
        "            n = 7\n",
        "            result = text[6: n + 11]\n",
        "            y_train.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {filename}: {str(e)}\")\n",
        "\n",
        "# Convert the training data to numpy arrays\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_train=x_train.astype('float32')/255.0\n",
        "x_train = x_train.reshape(x_train.shape[0], 32, 32, 1) #1채널 형태로 바꿔야함(data processing에서 중요)\n",
        "input_shape = (32,32,1)\n",
        "\n",
        "Tmp=output_list\n",
        "\n",
        "# Determine the class for each label\n",
        "y_train_classes = []\n",
        "for label in y_train:\n",
        "    label=int(label)\n",
        "    if label < Tmp[0]:\n",
        "        class_index = 0\n",
        "    elif Tmp[0] <= label < Tmp[1]:\n",
        "        class_index = 1\n",
        "    elif Tmp[1] <= label < Tmp[2]:\n",
        "        class_index = 2\n",
        "    elif Tmp[2] <= label < Tmp[3]:\n",
        "        class_index = 3\n",
        "    elif Tmp[3] <= label < Tmp[4]:\n",
        "        class_index = 4\n",
        "    elif Tmp[4] <= label < Tmp[5]:\n",
        "        class_index = 5\n",
        "    else:\n",
        "        class_index = 6\n",
        "    y_train_classes.append(class_index)\n",
        "\n",
        "# Convert the class labels to one-hot encoded vectors\n",
        "num_classes = len(Tmp) + 1\n",
        "y_train_one_hot = keras.utils.to_categorical(y_train_classes, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train2 labeling 및 전처리\n",
        "text = \"root1_221121150621.jpg\"\n",
        "n = 7\n",
        "result = text[6:n+11]\n",
        "date_time = datetime.strptime(result, \"%y%m%d%H%M%S\")\n",
        "formatted_date_time = date_time.strftime(\"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
        "\n",
        "output_list = []\n",
        "\n",
        "for _ in range(6):\n",
        "    delta = timedelta(minutes=720)\n",
        "\n",
        "    # 시간 증가\n",
        "    new_date_time = date_time + delta\n",
        "\n",
        "    # 증가된 시간 출력\n",
        "    formatted_date_time = new_date_time.strftime(\"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
        "\n",
        "    date_time = datetime.strptime(formatted_date_time, \"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
        "    formatted_number = date_time.strftime(\"%y%m%d%H%M%S\")\n",
        "\n",
        "    output_list.append(int(formatted_number))\n",
        "\n",
        "image_directory = \"/content/drive/MyDrive/root1_221121_훌륭\"\n",
        "\n",
        "x_train1 = []\n",
        "y_train = []\n",
        "\n",
        "# Iterate over the files in the directory\n",
        "for filename in os.listdir(image_directory):\n",
        "    # Read the image\n",
        "    image = cv2.imread(os.path.join(image_directory, filename))\n",
        "    \n",
        "    # Check if image is not empty\n",
        "    if image is not None:\n",
        "        # Resize the image to match the MNIST dataset size (32x32 pixels)\n",
        "        try:\n",
        "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            gray_image  = gray_image[:, 80:-60] \n",
        "            gray_image = cv2.resize(gray_image, (32, 32))\n",
        " \n",
        "            x_train1.append(gray_image)\n",
        "            text = filename\n",
        "            n = 7\n",
        "            result = text[6: n + 11]\n",
        "            y_train.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {filename}: {str(e)}\")\n",
        "\n",
        "# Convert the training data to numpy arrays\n",
        "x_train1 = np.array(x_train1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_train1=x_train1.astype('float32')/255.0\n",
        "x_train1 = x_train1.reshape(x_train1.shape[0], 32, 32, 1) #1채널 형태로 바꿔야함(data processing에서 중요)\n",
        "input_shape = (32,32,1)\n",
        "\n",
        "#train 데이터 catergorical labeling을 위해 one-hot encoding\n",
        "t1_tmp=output_list\n",
        "\n",
        "# Determine the class for each label\n",
        "y_train_classes = []\n",
        "for label in y_train:\n",
        "    label=int(label)\n",
        "    if label < t1_tmp[0]:\n",
        "        class_index = 0\n",
        "    elif t1_tmp[0] <= label < t1_tmp[1]:\n",
        "        class_index = 1\n",
        "    elif t1_tmp[1] <= label < t1_tmp[2]:\n",
        "        class_index = 2\n",
        "    elif t1_tmp[2] <= label < t1_tmp[3]:\n",
        "        class_index = 3\n",
        "    elif t1_tmp[3] <= label < t1_tmp[4]:\n",
        "        class_index = 4\n",
        "    elif t1_tmp[4] <= label < t1_tmp[5]:\n",
        "        class_index = 5\n",
        "    else:\n",
        "        class_index = 6\n",
        "    y_train_classes.append(class_index)\n",
        "\n",
        "# Convert the class labels to one-hot encoded vectors\n",
        "num_classes = len(t1_tmp) + 1\n",
        "y_train1_one_hot = keras.utils.to_categorical(y_train_classes, num_classes)"
      ],
      "metadata": {
        "id": "bXHJ12dEAWP3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PbNhGDTZs_op"
      },
      "outputs": [],
      "source": [
        "#test labeling 및 전처리\n",
        "text = \"root1_220923114836.jpg\"\n",
        "\n",
        "n = 7\n",
        "result = text[6:n+11]\n",
        "date_time = datetime.strptime(result, \"%y%m%d%H%M%S\")\n",
        "formatted_date_time = date_time.strftime(\"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
        "\n",
        "test_output_list = []\n",
        "\n",
        "for _ in range(6):\n",
        "    delta = timedelta(minutes=720)\n",
        "\n",
        "    # 시간 증가\n",
        "    new_date_time = date_time + delta\n",
        "\n",
        "    # 증가된 시간 출력\n",
        "    formatted_date_time = new_date_time.strftime(\"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
        "\n",
        "    date_time = datetime.strptime(formatted_date_time, \"%Y년 %m월 %d일 %H시 %M분 %S초\")\n",
        "    formatted_number = date_time.strftime(\"%y%m%d%H%M%S\")\n",
        "\n",
        "\n",
        "    test_output_list.append(int(formatted_number))\n",
        "\n",
        "image_directory = \"/content/drive/MyDrive/root1_220923\"\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "# Iterate over the files in the directory\n",
        "for filename in os.listdir(image_directory):\n",
        "    # Read the image\n",
        "    image = cv2.imread(os.path.join(image_directory, filename))\n",
        "    \n",
        "    # Check if image is not empty\n",
        "    if image is not None:\n",
        "        # Resize the image to match the MNIST dataset size (32x32 pixels)\n",
        "        try:\n",
        "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            gray_image  = gray_image[:, 80:-60] \n",
        "            gray_image = cv2.resize(gray_image, (32, 32))\n",
        "            x_test.append(gray_image)\n",
        "            text = filename\n",
        "            n = 7\n",
        "            result = text[6: n + 11]\n",
        "            y_test.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {filename}: {str(e)}\")\n",
        "\n",
        "# Convert the testing data to numpy arrays\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "x_test = x_test.astype('float32')/255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], 32, 32, 1) #1채널 형태로 바꿔야함(data processing에서 중요)\n",
        "input_shape = (32,32,1)\n",
        "\n",
        "test_tmp= test_output_list\n",
        "\n",
        "# Determine the class for each label\n",
        "y_test_classes = []\n",
        "\n",
        "for label in y_test:\n",
        "    label=int(label)\n",
        "    if label < test_tmp[0]:\n",
        "        class_index = 0\n",
        "    elif test_tmp[0] <= label < test_tmp[1]:\n",
        "        class_index = 1\n",
        "    elif test_tmp[1] <= label < test_tmp[2]:\n",
        "        class_index = 2\n",
        "    elif test_tmp[2] <= label < test_tmp[3]:\n",
        "        class_index = 3\n",
        "    elif test_tmp[3] <= label < test_tmp[4]:\n",
        "        class_index = 4\n",
        "    elif test_tmp[4] <= label < test_tmp[5]:\n",
        "        class_index = 5\n",
        "    else:\n",
        "        class_index = 6        \n",
        "    y_test_classes.append(class_index)\n",
        "\n",
        "# Convert the class labels to one-hot encoded vectors\n",
        "num_classes = len(test_tmp) + 1\n",
        "y_test_one_hot = keras.utils.to_categorical(y_test_classes, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "U_FTlfr2j6lV"
      },
      "outputs": [],
      "source": [
        "#cnn model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), padding='same',activation='relu',input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(64, (2, 2), activation='relu', padding='same')) #64채널에 \n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #특징들의 확률을 확실히 정함\n",
        "model.add(Dropout(0.25)) #트레인 튜런중 일부를 꺼서 오버피팅 막음\n",
        "model.add(Flatten())  #각 레이어를 통해 추출된 특징들을 2차원에서 1차원으로 바꿔 fully connected layer에 들어가기 전 바꾼다\n",
        "model.add(Dense(1000, activation='relu')) #입력받는 노드들과 출력으로 나가는 노드들의 개수를 받아 연결한다\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uWK8PW-j7nw"
      },
      "outputs": [],
      "source": [
        "#train 데이터를 fitting\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "\n",
        "train_accs = []\n",
        "train_losses = []\n",
        "test_accs = []\n",
        "test_losses = []\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "x_combined = np.concatenate((x_train, x_train1), axis=0)\n",
        "y_combined = np.concatenate((y_train_one_hot, y_train1_one_hot), axis=0)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"epoch\", epoch+1)\n",
        "  model.fit(x_combined, y_combined, batch_size=batch_size,verbose=1)\n",
        "\n",
        "  train_metrics = model.evaluate(x_combined, y_combined, verbose=0)\n",
        "  train_accs.append(train_metrics[1]) \n",
        "  train_losses.append(train_metrics[0])\n",
        "\n",
        "  test_metrics = model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
        "  test_accs.append(test_metrics[1])\n",
        "  test_losses.append(test_metrics[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYN8gklpj8r2"
      },
      "outputs": [],
      "source": [
        "#fitting된 모델로 train_data 예측 실시\n",
        "predicted_result = model.predict(x_combined)\n",
        "predicted_labels = np.argmax(predicted_result, axis=1)\n",
        "\n",
        "test_labels = np.argmax(y_combined, axis=1)\n",
        "wrong_result = []\n",
        "\n",
        "samples = random.sample(range(501), 16)\n",
        "\n",
        "count = 0\n",
        "nrows = ncols = 4\n",
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "for n in samples:\n",
        "    count += 1\n",
        "    plt.subplot(nrows, ncols, count)\n",
        "    plt.imshow(x_combined[n], cmap='Greys', interpolation='nearest')\n",
        "    tmp = \"Label:\" + str(test_labels[n]) + \", Prediction:\" + str(predicted_labels[n])\n",
        "    plt.title(tmp)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsGDJZ7BkAZv"
      },
      "outputs": [],
      "source": [
        "#fitting된 모델로 test_data 예측 실시\n",
        "predicted_result = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predicted_result, axis=1)\n",
        "\n",
        "test_labels = np.argmax(y_test_one_hot, axis=1)\n",
        "wrong_result = []\n",
        "\n",
        "random_numbers = random.sample(range(501), 16)\n",
        "  \n",
        "count = 0\n",
        "nrows = ncols = 4\n",
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "for n in random_numbers:\n",
        "    count += 1\n",
        "    plt.subplot(nrows, ncols, count)\n",
        "    plt.imshow(x_test[n], cmap='Greys', interpolation='nearest')\n",
        "    tmp = \"Label:\" + str(test_labels[n]) + \", Prediction:\" + str(predicted_labels[n])\n",
        "    plt.title(tmp)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(train_losses)\n",
        "plt.plot(test_losses)\n",
        "plt.plot(train_accs)\n",
        "plt.plot(test_accs)\n",
        "plt.legend(['train_losses', 'test_losses', 'train_accuracy', 'test_accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yMxolbfTN9kl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}